{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Датасет с ирисами: классификация и градиентный спуск",
   "id": "7afd329d7ee5b460"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Загружаю датасет",
   "id": "529f7061adf0f1cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:01:35.257900Z",
     "start_time": "2026-01-19T08:01:35.244824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Загружаем датасет\n",
    "iris = load_iris()\n",
    "\n",
    "# Сразу создаем DataFrame и фильтруем\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "\n",
    "# Оставляем только классы 1 (Versicolor) и 2 (Virginica)\n",
    "filtered_df = iris_df[iris_df['target'] >= 1].copy()\n",
    "\n",
    "# Для ясности добавляем названия классов\n",
    "class_names = {1: 'versicolor', 2: 'virginica'}\n",
    "filtered_df['target_name'] = filtered_df['target'].map(class_names)\n",
    "\n",
    "print(\"Отфильтрованный датасет (2 класса):\")\n",
    "print(f\"Размер: {len(filtered_df)} записей\")\n",
    "print(f\"\\nРаспределение классов:\")\n",
    "print(filtered_df['target_name'].value_counts())\n",
    "print(f\"\\nПропорции: {filtered_df['target_name'].value_counts(normalize=True).round(2).to_dict()}\")"
   ],
   "id": "97abaa08c6225f7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отфильтрованный датасет (2 класса):\n",
      "Размер: 100 записей\n",
      "\n",
      "Распределение классов:\n",
      "target_name\n",
      "versicolor    50\n",
      "virginica     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Пропорции: {'versicolor': 0.5, 'virginica': 0.5}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Логистическая регрессия",
   "id": "8f6bae444379ec47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:06:04.356096Z",
     "start_time": "2026-01-19T08:06:04.349518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            # Прямое распространение\n",
    "            linear = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self._sigmoid(linear)\n",
    "\n",
    "            # Градиенты\n",
    "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Обновление параметров\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        linear = np.dot(X, self.weights) + self.bias\n",
    "        return self._sigmoid(linear)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)"
   ],
   "id": "b93a609e8dfa906f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Использование",
   "id": "bc2953b81c7cf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:06:09.564060Z",
     "start_time": "2026-01-19T08:06:09.155334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Пример с данными ирисов\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Загружаем и фильтруем данные\n",
    "iris = load_iris()\n",
    "X = iris.data[iris.target != 0]\n",
    "y = iris.target[iris.target != 0]\n",
    "y = y - 1  # 0 и 1 вместо 1 и 2\n",
    "\n",
    "# Разделяем данные\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем и обучаем модель\n",
    "model = LogisticRegression(learning_rate=0.1, n_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Точность\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Точность: {accuracy:.4f}\")"
   ],
   "id": "8697bf8fdd5fb195",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.8500\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Метод градиентного спуска",
   "id": "8ac38111e59b86e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:07:21.890635Z",
     "start_time": "2026-01-19T08:07:21.830801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegressionGD:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.loss_history = []\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "    def _compute_loss(self, y_true, y_pred):\n",
    "        # Log loss (binary cross entropy)\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        self.loss_history = []\n",
    "\n",
    "        # Градиентный спуск\n",
    "        for i in range(self.n_iterations):\n",
    "            # Прямое распространение\n",
    "            linear = X @ self.w + self.b\n",
    "            y_pred = self._sigmoid(linear)\n",
    "\n",
    "            # Вычисление потерь\n",
    "            loss = self._compute_loss(y, y_pred)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            # Градиенты\n",
    "            dw = (1 / n_samples) * (X.T @ (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Обновление параметров\n",
    "            self.w -= self.lr * dw\n",
    "            self.b -= self.lr * db\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        linear = X @ self.w + self.b\n",
    "        return self._sigmoid(linear)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "# Метрика качества - точность (accuracy)\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Данные ирисов (Versicolor и Virginica)\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Загрузка и подготовка данных\n",
    "    iris = load_iris()\n",
    "    X = iris.data[iris.target != 0]  # Только 2 класса\n",
    "    y = iris.target[iris.target != 0]\n",
    "    y = y - 1  # Преобразуем в 0 и 1\n",
    "\n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Масштабирование\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Создание и обучение модели\n",
    "    model = LogisticRegressionGD(learning_rate=0.1, n_iterations=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Предсказания\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Расчет метрики\n",
    "    accuracy = calculate_accuracy(y_test, y_pred)\n",
    "\n",
    "    # Вывод результатов\n",
    "    print(f\"Точность (accuracy) на тестовой выборке: {accuracy:.4f}\")\n",
    "    print(f\"Финальная loss: {model.loss_history[-1]:.6f}\")"
   ],
   "id": "6469a78e755782",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность (accuracy) на тестовой выборке: 0.8000\n",
      "Финальная loss: 0.050086\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Метод скользящего среднего (Root Mean Square Propagation, RMSProp)",
   "id": "2786855e9e83aa44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T08:08:44.076280Z",
     "start_time": "2026-01-19T08:08:44.009783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegressionRMSProp:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, beta=0.9, epsilon=1e-8):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.beta = beta\n",
    "        self.epsilon = epsilon\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.loss_history = []\n",
    "\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "    def _compute_loss(self, y_true, y_pred):\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        self.loss_history = []\n",
    "\n",
    "        # Инициализация для RMSProp\n",
    "        s_w = np.zeros(n_features)  # для весов\n",
    "        s_b = 0                     # для смещения\n",
    "\n",
    "        # Градиентный спуск с RMSProp\n",
    "        for i in range(self.n_iterations):\n",
    "            # Прямое распространение\n",
    "            linear = X @ self.w + self.b\n",
    "            y_pred = self._sigmoid(linear)\n",
    "\n",
    "            # Вычисление потерь\n",
    "            loss = self._compute_loss(y, y_pred)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            # Градиенты\n",
    "            dw = (1 / n_samples) * (X.T @ (y_pred - y))\n",
    "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # RMSProp: обновление скользящих средних квадратов градиентов\n",
    "            s_w = self.beta * s_w + (1 - self.beta) * (dw ** 2)\n",
    "            s_b = self.beta * s_b + (1 - self.beta) * (db ** 2)\n",
    "\n",
    "            # Обновление параметров с адаптивным шагом\n",
    "            self.w -= self.lr * dw / (np.sqrt(s_w) + self.epsilon)\n",
    "            self.b -= self.lr * db / (np.sqrt(s_b) + self.epsilon)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        linear = X @ self.w + self.b\n",
    "        return self._sigmoid(linear)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "# Метрика качества - точность (accuracy)\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Данные ирисов (Versicolor и Virginica)\n",
    "    from sklearn.datasets import load_iris\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    # Загрузка и подготовка данных\n",
    "    iris = load_iris()\n",
    "    X = iris.data[iris.target != 0]\n",
    "    y = iris.target[iris.target != 0]\n",
    "    y = y - 1\n",
    "\n",
    "    # Разделение данных\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Масштабирование\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Создание и обучение модели с RMSProp\n",
    "    model = LogisticRegressionRMSProp(learning_rate=0.01, n_iterations=1000, beta=0.9)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Предсказания\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Расчет метрики\n",
    "    accuracy = calculate_accuracy(y_test, y_pred)\n",
    "\n",
    "    # Вывод результатов\n",
    "    print(f\"Точность (accuracy) на тестовой выборке: {accuracy:.4f}\")\n",
    "    print(f\"Финальная loss: {model.loss_history[-1]:.6f}\")"
   ],
   "id": "3e5122d5960b9f34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность (accuracy) на тестовой выборке: 0.8000\n",
      "Финальная loss: 0.009426\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
